{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b03c50c4",
   "metadata": {},
   "source": [
    "# Multiclass Classification\n",
    "\n",
    "In this notebook, we will explore the use of neural networks to solve the famous iris flowers classification problem. The attributes of the iris dataset can be summarized as:\n",
    "1. Sepal length (cm)\n",
    "2. Sepal width (cm)\n",
    "3. Petal length (cm)\n",
    "4. Petal length (cm)\n",
    "5. Class (target)\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b285d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow.keras.utils as tfu\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1688d5",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "382ad689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv', header=None)\n",
    "dataset = df.values\n",
    "X = dataset[:, 0:4].astype(float)\n",
    "y = dataset[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a5b7d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2e5085c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96204bf6",
   "metadata": {},
   "source": [
    "## Encoding the Output Variable\n",
    "\n",
    "The output variable contains three different values. We can reshape the output into a vector representing class identity via one-hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90d7aeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y = pd.get_dummies(y).to_numpy()\n",
    "dummy_y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1562e84",
   "metadata": {},
   "source": [
    "## Defining the Neural Network Model\n",
    "\n",
    "As before, we can use `KerasClassifier` to define our neural network. Unlike the previous example with one final output, we will naturally need to create three outputs, one representing each potential class value. \n",
    "\n",
    "4 inputs --> [8 hidden nodes] --> 3 outputs\n",
    "\n",
    "We will use a softmax activation function in the output layer. This is to ensure the output values are in the range of 0 and 1 and may be used as predicted probabilities. In the compilation step, we will need to alter the gradient descent function to account for the multiple value entropy being calculated. We can use `categorical_crossentropy` instead of the `binary_crossentropy` used in the binary classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "320c383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_shape=(4,), activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85886b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the KerasClassifier\n",
    "\n",
    "estimator = KerasClassifier(model=baseline_model, epochs=200, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bfbac3",
   "metadata": {},
   "source": [
    "## Evaluating the Model with *k*-Fold Cross-Validation\n",
    "\n",
    "We can use the gold standard for validation, *k*-Fold cross-validation. First, we will need to define the model evaluation procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fff6241",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94f087",
   "metadata": {},
   "source": [
    "Now we can evaluate our model on our dataset (`X` and `dummy_y`) using the 10-fold cross-validation procedure (`kfold`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10cc0917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.67% (4.47%)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a834a9",
   "metadata": {},
   "source": [
    "The results are summarized as both the mean and standard deviation of the model accuracy on the dataset. This is a reasonable estimation of the performance of the model on unseen data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
